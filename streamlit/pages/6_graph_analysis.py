import streamlit as st
import pandas as pd
import networkx as nx
import matplotlib.pyplot as plt
import japanize_matplotlib # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®ã‚µãƒãƒ¼ãƒˆ
import numpy as np
import sys
import os
from collections import Counter # Counterã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

# --- ãƒ‘ã‚¹è¨­å®š ---
current_dir = os.path.dirname(__file__) # ã“ã®è¡Œã¯Streamlitç’°å¢ƒã§ã¯ __file__ ãŒæœŸå¾…é€šã‚Šã«å‹•ä½œã—ãªã„ã“ã¨ãŒã‚ã‚‹ãŸã‚ã€ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œæ™‚ã®ã¿æœ‰åŠ¹
streamlit_dir = os.path.abspath(os.path.join(current_dir, '..'))
project_root_dir = os.path.abspath(os.path.join(streamlit_dir, '..'))
sys.path.append(project_root_dir)

from datagen.data_utils import generate_graph # å¿…è¦ã«å¿œã˜ã¦

st.set_page_config(layout="wide", page_title="ã‚°ãƒ©ãƒ•æ§‹é€ åˆ†æ")
st.title("ğŸ“Š ã‚°ãƒ©ãƒ•æ§‹é€ åˆ†æ") # ã‚¿ã‚¤ãƒˆãƒ«ã«çµµæ–‡å­—ã‚’è¿½åŠ 

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã®ã‚°ãƒ©ãƒ•é¸æŠ/ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ (å°†æ¥çš„ã«2ã¤å…¥åŠ›ã§ãã‚‹ã‚ˆã†ã«æ‹¡å¼µ) ---
st.sidebar.header("åˆ†æå¯¾è±¡ã‚°ãƒ©ãƒ•")

# ã‚°ãƒ©ãƒ•å¯è¦–åŒ–ã‚¿ãƒ–ã§ç”Ÿæˆã•ã‚ŒãŸã‚°ãƒ©ãƒ•ã‚’ä½¿ç”¨ã™ã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³
use_generated_graph = st.sidebar.checkbox("ã€Œã‚°ãƒ©ãƒ•å¯è¦–åŒ–ã€ã‚¿ãƒ–ã®ã‚°ãƒ©ãƒ•ã‚’ä½¿ç”¨ã™ã‚‹", value=True, key="ga_use_generated")

graph_sources = {} # åˆ†æå¯¾è±¡ã‚°ãƒ©ãƒ•ã‚’æ ¼ç´ã™ã‚‹è¾æ›¸ {name: G_object}

if use_generated_graph:
    graph_key = 'gv_graph' # ã‚°ãƒ©ãƒ•å¯è¦–åŒ–ãƒšãƒ¼ã‚¸ã§è¨­å®šã•ã‚ŒãŸã‚°ãƒ©ãƒ•ã®ã‚­ãƒ¼
    if graph_key in st.session_state and st.session_state[graph_key] is not None:
        G_main = st.session_state[graph_key]
        # ã‚°ãƒ©ãƒ•ãŒç©ºã§ãªã„ã‹ã€ã¾ãŸã¯Noneã§ãªã„ã‹ã‚’ç¢ºèª
        if G_main is not None and G_main.number_of_nodes() > 0 :
            graph_sources["ç”Ÿæˆã•ã‚ŒãŸã‚°ãƒ©ãƒ•"] = G_main
            st.sidebar.success("ã€Œã‚°ãƒ©ãƒ•å¯è¦–åŒ–ã€ã‚¿ãƒ–ã®ã‚°ãƒ©ãƒ•ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚")
        elif G_main is not None and G_main.number_of_nodes() == 0:
            st.sidebar.warning("ã€Œã‚°ãƒ©ãƒ•å¯è¦–åŒ–ã€ã‚¿ãƒ–ã®ã‚°ãƒ©ãƒ•ã¯ãƒãƒ¼ãƒ‰æ•°ãŒ0ã§ã™ã€‚")
            G_main = None # åˆ†æå¯¾è±¡å¤–ã¨ã™ã‚‹
        else:
            st.sidebar.warning("ã€Œã‚°ãƒ©ãƒ•å¯è¦–åŒ–ã€ã‚¿ãƒ–ã§ã‚°ãƒ©ãƒ•ãŒé©åˆ‡ã«ç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            G_main = None
    else:
        st.sidebar.warning("ã€Œã‚°ãƒ©ãƒ•å¯è¦–åŒ–ã€ã‚¿ãƒ–ã§ã‚°ãƒ©ãƒ•ãŒç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        G_main = None
else:
    # å°†æ¥çš„ã«ã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ãªã©ã‚’ã“ã“ã«è¿½åŠ 
    st.sidebar.info("ç¾åœ¨ã¯ã€Œã‚°ãƒ©ãƒ•å¯è¦–åŒ–ã€ã‚¿ãƒ–ã®ã‚°ãƒ©ãƒ•ã®ã¿åˆ©ç”¨å¯èƒ½ã§ã™ã€‚")
    G_main = None


# --- åˆ†æã®å®Ÿè¡Œã¨è¡¨ç¤º ---
if not graph_sources:
    st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§åˆ†æå¯¾è±¡ã®ã‚°ãƒ©ãƒ•ã‚’ãƒ­ãƒ¼ãƒ‰ã¾ãŸã¯ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")
    st.stop()

selected_graph_name = list(graph_sources.keys())[0]
G_to_analyze = graph_sources[selected_graph_name]

st.header(f"åˆ†æå¯¾è±¡: {selected_graph_name}")

if G_to_analyze is None or G_to_analyze.number_of_nodes() == 0:
    st.warning(f"åˆ†æå¯¾è±¡ã®ã‚°ãƒ©ãƒ•ã€Œ{selected_graph_name}ã€ã«ãƒãƒ¼ãƒ‰ãŒãªã„ã‹ã€ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop()

# --- 1. åŸºæœ¬çµ±è¨ˆé‡ ---
st.subheader("1. ğŸ“ˆ åŸºæœ¬çµ±è¨ˆé‡")
num_nodes = G_to_analyze.number_of_nodes()
num_edges = G_to_analyze.number_of_edges()
st.write(f"- ãƒãƒ¼ãƒ‰æ•° (ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°): {num_nodes}")
st.write(f"- ã‚¨ãƒƒã‚¸æ•° (ãƒ•ã‚©ãƒ­ãƒ¼é–¢ä¿‚æ•°): {num_edges}")

if num_nodes > 0:
    # å¹³å‡æ¬¡æ•°
    if G_to_analyze.is_directed():
        in_degrees_list = [d for n, d in G_to_analyze.in_degree()]
        out_degrees_list = [d for n, d in G_to_analyze.out_degree()]
        avg_in_degree = sum(in_degrees_list) / num_nodes if num_nodes > 0 else 0
        avg_out_degree = sum(out_degrees_list) / num_nodes if num_nodes > 0 else 0
        st.write(f"- å¹³å‡å…¥æ¬¡æ•° (å¹³å‡ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°): {avg_in_degree:.2f}")
        st.write(f"- å¹³å‡å‡ºæ¬¡æ•° (å¹³å‡ãƒ•ã‚©ãƒ­ãƒ¼æ•°): {avg_out_degree:.2f}")
        degrees_list = in_degrees_list + out_degrees_list # ç·åˆçš„ãªæ¬¡æ•°ã¨ã—ã¦
    else:
        degrees_list = [d for n, d in G_to_analyze.degree()]
        avg_degree = sum(degrees_list) / num_nodes if num_nodes > 0 else 0
        st.write(f"- å¹³å‡æ¬¡æ•°: {avg_degree:.2f}")

    # å¯†åº¦
    density = nx.density(G_to_analyze)
    max_possible_edges_formula = "N*(N-1)" if G_to_analyze.is_directed() else "N*(N-1)/2"
    max_possible_edges = num_nodes * (num_nodes - 1) if G_to_analyze.is_directed() else num_nodes * (num_nodes - 1) / 2
    max_possible_edges = max(1, max_possible_edges) # 0é™¤ç®—ã‚’é¿ã‘ã‚‹
    st.write(f"- å¯†åº¦: {density:.4f} (æœ€å¤§å¯èƒ½ã‚¨ãƒƒã‚¸æ•° {max_possible_edges_formula}: {int(max_possible_edges)})")

    # æ¬¡æ•°åˆ†å¸ƒ
    st.markdown("**æ¬¡æ•°åˆ†å¸ƒ (Degree Distribution)**")
    
    # æ¬¡æ•°ã®çµ±è¨ˆçš„è¨˜è¿°
    if degrees_list: # degrees_listãŒç©ºã§ãªã„ã“ã¨ã‚’ç¢ºèª
        st.write(f"  - æ¬¡æ•°ã®ä¸­å¤®å€¤: {np.median(degrees_list):.2f}, æœ€å¤§æ¬¡æ•°: {np.max(degrees_list)}, æœ€å°æ¬¡æ•°: {np.min(degrees_list)}")

    cols_deg_hist = st.columns(2 if G_to_analyze.is_directed() else 1)
    bin_count = max(1, min(30, int(num_nodes/10) if num_nodes > 10 else num_nodes)) # ãƒ“ãƒ³æ•°ã‚’èª¿æ•´

    if G_to_analyze.is_directed():
        with cols_deg_hist[0]:
            st.write("å…¥æ¬¡æ•°åˆ†å¸ƒ (ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°)")
            fig_in_deg, ax_in_deg = plt.subplots()
            ax_in_deg.hist(in_degrees_list, bins=bin_count, rwidth=0.9, color='skyblue', edgecolor='black')
            ax_in_deg.set_xlabel("å…¥æ¬¡æ•°")
            ax_in_deg.set_ylabel("ãƒãƒ¼ãƒ‰æ•°")
            ax_in_deg.grid(axis='y', alpha=0.75)
            st.pyplot(fig_in_deg)

        with cols_deg_hist[1]:
            st.write("å‡ºæ¬¡æ•°åˆ†å¸ƒ (ãƒ•ã‚©ãƒ­ãƒ¼æ•°)")
            fig_out_deg, ax_out_deg = plt.subplots()
            ax_out_deg.hist(out_degrees_list, bins=bin_count, rwidth=0.9, color='lightcoral', edgecolor='black')
            ax_out_deg.set_xlabel("å‡ºæ¬¡æ•°")
            ax_out_deg.set_ylabel("ãƒãƒ¼ãƒ‰æ•°")
            ax_out_deg.grid(axis='y', alpha=0.75)
            st.pyplot(fig_out_deg)
        
        # ä¸¡å¯¾æ•°ãƒ—ãƒ­ãƒƒãƒˆ (æ¬¡æ•°åˆ†å¸ƒãŒã¹ãä¹—å‰‡ã«å¾“ã†ã‹ç¢ºèª)
        st.markdown("**æ¬¡æ•°åˆ†å¸ƒã®ä¸¡å¯¾æ•°ãƒ—ãƒ­ãƒƒãƒˆ (Log-Log Scale)**")
        cols_loglog = st.columns(2)
        with cols_loglog[0]:
            in_degree_counts = Counter(in_degrees_list)
            if in_degree_counts: # CounterãŒç©ºã§ãªã„ã“ã¨ã‚’ç¢ºèª
                in_deg, in_cnt = zip(*sorted(in_degree_counts.items()))
                fig_in_log, ax_in_log = plt.subplots()
                ax_in_log.loglog(in_deg, in_cnt, marker='o', linestyle='none', color='skyblue')
                ax_in_log.set_xlabel("å…¥æ¬¡æ•° (Log Scale)")
                ax_in_log.set_ylabel("ãƒãƒ¼ãƒ‰æ•° (Log Scale)")
                ax_in_log.set_title("å…¥æ¬¡æ•° (Log-Log)")
                ax_in_log.grid(True, which="both", ls="-", alpha=0.5)
                st.pyplot(fig_in_log)
            else:
                st.write("å…¥æ¬¡æ•°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        with cols_loglog[1]:
            out_degree_counts = Counter(out_degrees_list)
            if out_degree_counts: # CounterãŒç©ºã§ãªã„ã“ã¨ã‚’ç¢ºèª
                out_deg, out_cnt = zip(*sorted(out_degree_counts.items()))
                fig_out_log, ax_out_log = plt.subplots()
                ax_out_log.loglog(out_deg, out_cnt, marker='o', linestyle='none', color='lightcoral')
                ax_out_log.set_xlabel("å‡ºæ¬¡æ•° (Log Scale)")
                ax_out_log.set_ylabel("ãƒãƒ¼ãƒ‰æ•° (Log Scale)")
                ax_out_log.set_title("å‡ºæ¬¡æ•° (Log-Log)")
                ax_out_log.grid(True, which="both", ls="-", alpha=0.5)
                st.pyplot(fig_out_log)
            else:
                st.write("å‡ºæ¬¡æ•°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")


    else: # ç„¡å‘ã‚°ãƒ©ãƒ•ã®å ´åˆ
        with cols_deg_hist[0]:
            st.write("æ¬¡æ•°åˆ†å¸ƒ")
            fig_deg, ax_deg = plt.subplots()
            ax_deg.hist(degrees_list, bins=bin_count, rwidth=0.9, color='mediumseagreen', edgecolor='black')
            ax_deg.set_xlabel("æ¬¡æ•°")
            ax_deg.set_ylabel("ãƒãƒ¼ãƒ‰æ•°")
            ax_deg.grid(axis='y', alpha=0.75)
            st.pyplot(fig_deg)

        st.markdown("**æ¬¡æ•°åˆ†å¸ƒã®ä¸¡å¯¾æ•°ãƒ—ãƒ­ãƒƒãƒˆ (Log-Log Scale)**")
        degree_counts = Counter(degrees_list)
        if degree_counts: # CounterãŒç©ºã§ãªã„ã“ã¨ã‚’ç¢ºèª
            deg, cnt = zip(*sorted(degree_counts.items()))
            fig_log, ax_log = plt.subplots()
            ax_log.loglog(deg, cnt, marker='o', linestyle='none', color='mediumseagreen')
            ax_log.set_xlabel("æ¬¡æ•° (Log Scale)")
            ax_log.set_ylabel("ãƒãƒ¼ãƒ‰æ•° (Log Scale)")
            ax_log.set_title("æ¬¡æ•° (Log-Log)")
            ax_log.grid(True, which="both", ls="-", alpha=0.5)
            st.pyplot(fig_log)
        else:
            st.write("æ¬¡æ•°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")


st.markdown("---")
# --- 2. ã‚°ãƒ©ãƒ•æ§‹é€ ã®æ€§è³ª ---
st.subheader("2. ğŸ”— ã‚°ãƒ©ãƒ•æ§‹é€ ã®æ€§è³ª")
# é€£çµæ€§
st.markdown("**é€£çµæ€§ (Connectivity)**")
if G_to_analyze.is_directed():
    num_sccs = nx.number_strongly_connected_components(G_to_analyze)
    sccs = list(nx.strongly_connected_components(G_to_analyze))
    largest_scc_size = len(max(sccs, key=len)) if sccs else 0
    st.write(f"- å¼·é€£çµæˆåˆ† (SCCs) ã®æ•°: {num_sccs}")
    st.write(f"- æœ€å¤§å¼·é€£çµæˆåˆ†ã®ã‚µã‚¤ã‚º: {largest_scc_size} ({largest_scc_size/num_nodes*100 if num_nodes > 0 else 0:.1f}%)")
    if num_sccs == 1 and largest_scc_size == num_nodes:
        st.success("  - âœ… ã“ã®ã‚°ãƒ©ãƒ•ã¯å¼·é€£çµã§ã™ï¼ˆæ—¢ç´„ï¼‰ã€‚")
    if sccs:
        scc_sizes = [len(s) for s in sccs]
        fig_scc, ax_scc = plt.subplots()
        ax_scc.hist(scc_sizes, bins=max(1, min(10, len(scc_sizes))), rwidth=0.9, color='cyan', edgecolor='black')
        ax_scc.set_title("å¼·é€£çµæˆåˆ†ã®ã‚µã‚¤ã‚ºåˆ†å¸ƒ")
        ax_scc.set_xlabel("SCCã‚µã‚¤ã‚º")
        ax_scc.set_ylabel("SCCæ•°")
        st.pyplot(fig_scc)


    num_wccs = nx.number_weakly_connected_components(G_to_analyze)
    wccs = list(nx.weakly_connected_components(G_to_analyze))
    largest_wcc_size = len(max(wccs, key=len)) if wccs else 0
    st.write(f"- å¼±é€£çµæˆåˆ† (WCCs) ã®æ•°: {num_wccs}")
    st.write(f"- æœ€å¤§å¼±é€£çµæˆåˆ†ã®ã‚µã‚¤ã‚º: {largest_wcc_size} ({largest_wcc_size/num_nodes*100 if num_nodes > 0 else 0:.1f}%)")
    if num_wccs == 1 and largest_wcc_size == num_nodes:
        st.success("  - âœ… ã“ã®ã‚°ãƒ©ãƒ•ã¯å¼±é€£çµã§ã™ã€‚")
    if wccs:
        wcc_sizes = [len(s) for s in wccs]
        fig_wcc, ax_wcc = plt.subplots()
        ax_wcc.hist(wcc_sizes, bins=max(1, min(10, len(wcc_sizes))), rwidth=0.9, color='magenta', edgecolor='black')
        ax_wcc.set_title("å¼±é€£çµæˆåˆ†ã®ã‚µã‚¤ã‚ºåˆ†å¸ƒ")
        ax_wcc.set_xlabel("WCCã‚µã‚¤ã‚º")
        ax_wcc.set_ylabel("WCCæ•°")
        st.pyplot(fig_wcc)


else: # ç„¡å‘ã‚°ãƒ©ãƒ•
    num_ccs = nx.number_connected_components(G_to_analyze)
    ccs = list(nx.connected_components(G_to_analyze))
    largest_cc_size = len(max(ccs, key=len)) if ccs else 0
    st.write(f"- é€£çµæˆåˆ†ã®æ•°: {num_ccs}")
    st.write(f"- æœ€å¤§é€£çµæˆåˆ†ã®ã‚µã‚¤ã‚º: {largest_cc_size} ({largest_cc_size/num_nodes*100 if num_nodes > 0 else 0:.1f}%)")
    if num_ccs == 1 and largest_cc_size == num_nodes:
        st.success("  - âœ… ã“ã®ã‚°ãƒ©ãƒ•ã¯é€£çµã§ã™ã€‚")
    if ccs:
        cc_sizes = [len(s) for s in ccs]
        fig_cc, ax_cc = plt.subplots()
        ax_cc.hist(cc_sizes, bins=max(1, min(10, len(cc_sizes))), rwidth=0.9, color='orange', edgecolor='black')
        ax_cc.set_title("é€£çµæˆåˆ†ã®ã‚µã‚¤ã‚ºåˆ†å¸ƒ")
        ax_cc.set_xlabel("CCã‚µã‚¤ã‚º")
        ax_cc.set_ylabel("CCæ•°")
        st.pyplot(fig_cc)

    # ãƒ–ãƒªãƒƒã‚¸ã¨é–¢ç¯€ç‚¹ã®æ¤œå‡º (ç„¡å‘ã‚°ãƒ©ãƒ•ã®ã¿)
    if num_nodes < 500: # è¨ˆç®—é‡ãŒå¤šã„ã®ã§åˆ¶é™
        try:
            if num_nodes > 0: # ãƒãƒ¼ãƒ‰ãŒãªã„ã¨ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ãŸã‚
                bridges = list(nx.bridges(G_to_analyze))
                articulation_points = list(nx.articulation_points(G_to_analyze))
                st.write(f"- ãƒ–ãƒªãƒƒã‚¸ (é™¤å»ã§é€£çµæˆåˆ†ãŒå¢—ãˆã‚‹ã‚¨ãƒƒã‚¸) ã®æ•°: {len(bridges)}")
                st.write(f"- é–¢ç¯€ç‚¹ (é™¤å»ã§é€£çµæˆåˆ†ãŒå¢—ãˆã‚‹ãƒãƒ¼ãƒ‰) ã®æ•°: {len(articulation_points)}")
            else:
                st.write("- ãƒ–ãƒªãƒƒã‚¸/é–¢ç¯€ç‚¹: ãƒãƒ¼ãƒ‰æ•°ãŒ0ã®ãŸã‚è¨ˆç®—ã§ãã¾ã›ã‚“ã€‚")
        except Exception as e:
            st.write(f"- ãƒ–ãƒªãƒƒã‚¸/é–¢ç¯€ç‚¹ã®è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
    else:
        st.write("- ãƒ–ãƒªãƒƒã‚¸/é–¢ç¯€ç‚¹: ã‚°ãƒ©ãƒ•ã‚µã‚¤ã‚ºãŒå¤§ãã„ãŸã‚è¨ˆç®—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã€‚")


# ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ä¿‚æ•°
st.markdown("**ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ä¿‚æ•° (Clustering Coefficient)**")
avg_clustering = nx.average_clustering(G_to_analyze)
st.write(f"- å¹³å‡ãƒ­ãƒ¼ã‚«ãƒ«ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ä¿‚æ•°: {avg_clustering:.4f}")

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ä¿‚æ•° (æ¨ç§»æ€§)
transitivity = nx.transitivity(G_to_analyze)
st.write(f"- ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ä¿‚æ•° (æ¨ç§»æ€§): {transitivity:.4f}")

# ãƒ­ãƒ¼ã‚«ãƒ«ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ä¿‚æ•°ã®åˆ†å¸ƒ
if num_nodes > 0:
    local_clustering_coeffs = list(nx.clustering(G_to_analyze).values())
    if local_clustering_coeffs: # ãƒªã‚¹ãƒˆãŒç©ºã§ãªã„ã“ã¨ã‚’ç¢ºèª
        fig_lcc, ax_lcc = plt.subplots()
        ax_lcc.hist(local_clustering_coeffs, bins=20, rwidth=0.9, color='gold', edgecolor='black')
        ax_lcc.set_title("ãƒ­ãƒ¼ã‚«ãƒ«ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ä¿‚æ•°ã®åˆ†å¸ƒ")
        ax_lcc.set_xlabel("ãƒ­ãƒ¼ã‚«ãƒ«ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ä¿‚æ•°")
        ax_lcc.set_ylabel("ãƒãƒ¼ãƒ‰æ•°")
        ax_lcc.grid(axis='y', alpha=0.75)
        st.pyplot(fig_lcc)
    else:
        st.write("ãƒ­ãƒ¼ã‚«ãƒ«ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ä¿‚æ•°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")


# å¹³å‡æœ€çŸ­çµŒè·¯é•·ã¨ç›´å¾„
st.markdown("**çµŒè·¯é•·ã¨ç›´å¾„ (Path Length & Diameter)**")
path_length_calculated = False
if num_nodes < 300 and num_nodes > 1: # ãƒãƒ¼ãƒ‰æ•°ãŒå°‘ãªã„(ã‹ã¤2ä»¥ä¸Š)å ´åˆã®ã¿è¨ˆç®—
    try:
        if G_to_analyze.is_directed():
            if sccs and largest_scc_size > 1 :
                largest_scc_graph = G_to_analyze.subgraph(max(sccs, key=len)).copy()
                if nx.is_strongly_connected(largest_scc_graph): # å¼·é€£çµã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
                     avg_shortest_path = nx.average_shortest_path_length(largest_scc_graph)
                     st.write(f"- å¹³å‡æœ€çŸ­çµŒè·¯é•· (æœ€å¤§SCCå†…, {largest_scc_graph.number_of_nodes()}ãƒãƒ¼ãƒ‰): {avg_shortest_path:.2f}")
                     path_length_calculated = True
                     # diameter = nx.diameter(largest_scc_graph) # ç›´å¾„ã‚‚åŒæ§˜
                     # st.write(f"- ç›´å¾„ (æœ€å¤§SCCå†…): {diameter}")
            # æœ€å¤§WCCãŒã‚°ãƒ©ãƒ•å…¨ä½“ã«è¿‘ãã€ãƒãƒ¼ãƒ‰æ•°ãŒè¤‡æ•°ã‚ã‚Œã°ã€æœ‰å‘ã®ã¾ã¾ã§è¨ˆç®—ã‚’è©¦ã¿ã‚‹
            elif wccs and largest_wcc_size > 1: # and largest_wcc_size > num_nodes * 0.5:
                largest_wcc_subgraph = G_to_analyze.subgraph(max(wccs, key=len))
                try:
                    avg_shortest_path_wcc_dir = nx.average_shortest_path_length(largest_wcc_subgraph)
                    st.write(f"- å¹³å‡æœ€çŸ­çµŒè·¯é•· (æœ€å¤§WCCå†…, æœ‰å‘, {largest_wcc_subgraph.number_of_nodes()}ãƒãƒ¼ãƒ‰): {avg_shortest_path_wcc_dir:.2f}")
                    path_length_calculated = True
                except nx.NetworkXError:
                     st.write(f"- å¹³å‡æœ€çŸ­çµŒè·¯é•· (æœ€å¤§WCCå†…, {largest_wcc_subgraph.number_of_nodes()}ãƒãƒ¼ãƒ‰): å¼±é€£çµæˆåˆ†ãŒå¼·é€£çµã§ãªã„ãŸã‚ã€ä¸€éƒ¨ã®ãƒãƒ¼ãƒ‰ãƒšã‚¢é–“ã§åˆ°é”ä¸å¯èƒ½ã§ã™ã€‚")

        else: # ç„¡å‘ã‚°ãƒ©ãƒ•
            if ccs and largest_cc_size > 1:
                largest_cc_graph = G_to_analyze.subgraph(max(ccs, key=len)).copy()
                if nx.is_connected(largest_cc_graph):
                    avg_shortest_path = nx.average_shortest_path_length(largest_cc_graph)
                    st.write(f"- å¹³å‡æœ€çŸ­çµŒè·¯é•· (æœ€å¤§é€£çµæˆåˆ†å†…, {largest_cc_graph.number_of_nodes()}ãƒãƒ¼ãƒ‰): {avg_shortest_path:.2f}")
                    path_length_calculated = True
                    # diameter = nx.diameter(largest_cc_graph)
                    # st.write(f"- ç›´å¾„ (æœ€å¤§é€£çµæˆåˆ†å†…): {diameter}")

        if not path_length_calculated:
            st.write("- å¹³å‡æœ€çŸ­çµŒè·¯é•·: è¨ˆç®—å¯¾è±¡ã®é©åˆ‡ãª(å¤§ããª)é€£çµ/å¼·é€£çµæˆåˆ†ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ã€è¨ˆç®—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

    except Exception as e:
        st.warning(f"- å¹³å‡æœ€çŸ­çµŒè·¯é•·/ç›´å¾„ã®è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
elif num_nodes <=1:
    st.write("- å¹³å‡æœ€çŸ­çµŒè·¯é•·/ç›´å¾„: ãƒãƒ¼ãƒ‰æ•°ãŒ1ä»¥ä¸‹ã®ãŸã‚è¨ˆç®—ã§ãã¾ã›ã‚“ã€‚")
else: # num_nodes >= 300
    st.write("- å¹³å‡æœ€çŸ­çµŒè·¯é•·/ç›´å¾„: ã‚°ãƒ©ãƒ•ã‚µã‚¤ã‚ºãŒå¤§ãã„ãŸã‚ã€ä¸»è¦ãªé€£çµæˆåˆ†ã§ã®è¨ˆç®—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")

# ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ§‹é€  (Louvainæ³•)
st.markdown("**ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ§‹é€  (Community Structure)**")
try:
    import community as community_louvain # python-louvain
    G_community_analysis = G_to_analyze
    
    if not G_to_analyze.is_directed() and G_community_analysis.number_of_nodes() > 0:
        partition = community_louvain.best_partition(G_community_analysis)
        num_communities = len(set(partition.values()))
        st.write(f"- Louvainæ³•ã«ã‚ˆã‚‹ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ¤œå‡º (ç„¡å‘ã‚°ãƒ©ãƒ•): {num_communities}å€‹ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£")
        if num_communities > 0 and num_communities < G_community_analysis.number_of_nodes(): # å…¨ãƒãƒ¼ãƒ‰ãŒåˆ¥ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¯é™¤ã
            modularity = community_louvain.modularity(partition, G_community_analysis)
            st.write(f"  - ãƒ¢ã‚¸ãƒ¥ãƒ©ãƒªãƒ†ã‚£: {modularity:.4f}")
            community_sizes_counter = Counter(partition.values())
            community_sizes_list = list(community_sizes_counter.values())
            
            fig_com, ax_com = plt.subplots()
            ax_com.hist(community_sizes_list, bins=max(1, min(20, num_communities)), rwidth=0.9, color='purple', edgecolor='black')
            ax_com.set_title("ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚µã‚¤ã‚ºåˆ†å¸ƒ (Louvain)")
            ax_com.set_xlabel("ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã‚µã‚¤ã‚º")
            ax_com.set_ylabel("ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ•°")
            st.pyplot(fig_com)
        elif num_communities == G_community_analysis.number_of_nodes():
            st.write("  - å„ãƒãƒ¼ãƒ‰ãŒå€‹åˆ¥ã®ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¨ã—ã¦æ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚")
        else:
            st.write("  - ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
    elif G_to_analyze.is_directed():
         st.write("- Louvainæ³•: æœ‰å‘ã‚°ãƒ©ãƒ•ã«ã¯ç›´æ¥é©ç”¨ã§ãã¾ã›ã‚“ã€‚ç„¡å‘ã‚°ãƒ©ãƒ•ã«å¤‰æ› (`G.to_undirected()`) ã—ã¦ãŠè©¦ã—ãã ã•ã„ã€‚")
    else: # ãƒãƒ¼ãƒ‰æ•°0ã®å ´åˆ
        st.write("- ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ§‹é€  (Louvainæ³•): ãƒãƒ¼ãƒ‰æ•°ãŒ0ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã€‚")

except ImportError:
    st.write("- ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ§‹é€  (Louvainæ³•): `python-louvain`ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ (`pip install python-louvain`)ã€‚")
except Exception as e:
    st.write(f"- ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ§‹é€ ã®è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

st.markdown("---")
# --- 3. ä¸­å¿ƒæ€§æŒ‡æ¨™ ---
st.subheader("3. ğŸŒŸ ä¸­å¿ƒæ€§æŒ‡æ¨™ (Centrality Measures)")
st.write("ä¸Šä½5ãƒãƒ¼ãƒ‰ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
k_top_centrality = 5

# æ¬¡æ•°ä¸­å¿ƒæ€§
st.markdown("**æ¬¡æ•°ä¸­å¿ƒæ€§ (Degree Centrality)**")
if G_to_analyze.is_directed():
    in_degree_centrality = nx.in_degree_centrality(G_to_analyze)
    top_in_degree = sorted(in_degree_centrality.items(), key=lambda x: x[1], reverse=True)[:k_top_centrality]
    st.write(f"- å…¥æ¬¡æ•°ä¸­å¿ƒæ€§: {[(n, f'{s:.3f}') for n, s in top_in_degree]}")

    out_degree_centrality = nx.out_degree_centrality(G_to_analyze)
    top_out_degree = sorted(out_degree_centrality.items(), key=lambda x: x[1], reverse=True)[:k_top_centrality]
    st.write(f"- å‡ºæ¬¡æ•°ä¸­å¿ƒæ€§: {[(n, f'{s:.3f}') for n, s in top_out_degree]}")
else:
    degree_centrality = nx.degree_centrality(G_to_analyze)
    top_degree = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)[:k_top_centrality]
    st.write(f"- æ¬¡æ•°ä¸­å¿ƒæ€§: {[(n, f'{s:.3f}') for n, s in top_degree]}")

# PageRank
st.markdown("**PageRank**")
if num_nodes > 0:
    try:
        pagerank = nx.pagerank(G_to_analyze, alpha=0.85, max_iter=100, tol=1.0e-6)
        top_pagerank = sorted(pagerank.items(), key=lambda x: x[1], reverse=True)[:k_top_centrality]
        st.write(f"- PageRank (alpha=0.85): {[(n, f'{s:.4f}') for n, s in top_pagerank]}")
    except nx.PowerIterationFailedConvergence:
        st.warning("- PageRank: è¨ˆç®—ãŒåæŸã—ã¾ã›ã‚“ã§ã—ãŸã€‚è©¦è¡Œå›æ•°ã‚’å¢—ã‚„ã™ã‹ã€è¨±å®¹èª¤å·®ã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")
    except Exception as e:
        st.error(f"- PageRankã®è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
else:
    st.write("- PageRank: ãƒãƒ¼ãƒ‰æ•°ãŒ0ã®ãŸã‚è¨ˆç®—ã§ãã¾ã›ã‚“ã€‚")


# HITS (Hubs and Authorities) - æœ‰å‘ã‚°ãƒ©ãƒ•ã®ã¿
if G_to_analyze.is_directed() and num_nodes > 0:
    st.markdown("**HITS (Hubs and Authorities)**")
    try:
        hubs, authorities = nx.hits(G_to_analyze, max_iter=100, tol=1.0e-6)
        top_hubs = sorted(hubs.items(), key=lambda x: x[1], reverse=True)[:k_top_centrality]
        top_authorities = sorted(authorities.items(), key=lambda x: x[1], reverse=True)[:k_top_centrality]
        st.write(f"- Hubã‚¹ã‚³ã‚¢ä¸Šä½: {[(n, f'{s:.4f}') for n, s in top_hubs]}")
        st.write(f"- Authorityã‚¹ã‚³ã‚¢ä¸Šä½: {[(n, f'{s:.4f}') for n, s in top_authorities]}")
    except nx.PowerIterationFailedConvergence:
        st.warning("- HITS: è¨ˆç®—ãŒåæŸã—ã¾ã›ã‚“ã§ã—ãŸã€‚")
    except Exception as e:
        st.error(f"- HITSã®è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
elif not G_to_analyze.is_directed():
    st.markdown("**HITS (Hubs and Authorities)**")
    st.write("- HITS: ç„¡å‘ã‚°ãƒ©ãƒ•ã®ãŸã‚é©ç”¨ã•ã‚Œã¾ã›ã‚“ (æœ‰å‘ã‚°ãƒ©ãƒ•ã®æŒ‡æ¨™ã§ã™)ã€‚")


# å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«ä¸­å¿ƒæ€§
st.markdown("**å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«ä¸­å¿ƒæ€§ (Eigenvector Centrality)**")
if num_nodes > 0:
    try:
        eigenvector_centrality = nx.eigenvector_centrality(G_to_analyze, max_iter=100, tol=1.0e-6)
        top_eigenvector = sorted(eigenvector_centrality.items(), key=lambda x: x[1], reverse=True)[:k_top_centrality]
        st.write(f"- å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«ä¸­å¿ƒæ€§: {[(n, f'{s:.4f}') for n, s in top_eigenvector]}")
    except nx.PowerIterationFailedConvergence:
         st.warning("- å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«ä¸­å¿ƒæ€§: è¨ˆç®—ãŒåæŸã—ã¾ã›ã‚“ã§ã—ãŸã€‚")
    except Exception as e: # Catch more general errors too, e.g. for disconnected graphs if not handled by nx
        st.error(f"- å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«ä¸­å¿ƒæ€§ã®è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
else:
    st.write("- å›ºæœ‰ãƒ™ã‚¯ãƒˆãƒ«ä¸­å¿ƒæ€§: ãƒãƒ¼ãƒ‰æ•°ãŒ0ã®ãŸã‚è¨ˆç®—ã§ãã¾ã›ã‚“ã€‚")


# åª’ä»‹ä¸­å¿ƒæ€§ (è¨ˆç®—é‡ãŒå¤šã„ã®ã§æ³¨æ„)
st.markdown("**åª’ä»‹ä¸­å¿ƒæ€§ (Betweenness Centrality)**")
if num_nodes < 200 and num_nodes > 2: # å°ã•ãªã‚°ãƒ©ãƒ•ã§ã®ã¿å…¨è¨ˆç®— (3ãƒãƒ¼ãƒ‰ä»¥ä¸Š)
    try:
        betweenness_centrality = nx.betweenness_centrality(G_to_analyze, normalized=True, endpoints=False)
        top_betweenness = sorted(betweenness_centrality.items(), key=lambda x: x[1], reverse=True)[:k_top_centrality]
        st.write(f"- åª’ä»‹ä¸­å¿ƒæ€§ (å…¨ãƒãƒ¼ãƒ‰): {[(n, f'{s:.4f}') for n, s in top_betweenness]}")
    except Exception as e:
        st.error(f"- åª’ä»‹ä¸­å¿ƒæ€§ã®è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
elif num_nodes >= 200 and num_nodes < 1000: # ä¸­è¦æ¨¡ã‚°ãƒ©ãƒ•ã§ã¯ã‚µãƒ³ãƒ—ãƒ«è¨ˆç®—
    try:
        sample_k = min(max(10, int(num_nodes * 0.1)), 100)
        betweenness_centrality_sampled = nx.betweenness_centrality(G_to_analyze, k=sample_k, normalized=True, endpoints=False)
        top_betweenness_sampled = sorted(betweenness_centrality_sampled.items(), key=lambda x: x[1], reverse=True)[:k_top_centrality]
        st.write(f"- åª’ä»‹ä¸­å¿ƒæ€§ (ã‚µãƒ³ãƒ—ãƒ«è¨ˆç®— k={sample_k}): {[(n, f'{s:.4f}') for n, s in top_betweenness_sampled]}")
    except Exception as e:
        st.error(f"- åª’ä»‹ä¸­å¿ƒæ€§ (ã‚µãƒ³ãƒ—ãƒ«è¨ˆç®—) ã®ã‚¨ãƒ©ãƒ¼: {e}")
elif num_nodes <= 2 and num_nodes > 0:
    st.write("- åª’ä»‹ä¸­å¿ƒæ€§: ãƒãƒ¼ãƒ‰æ•°ãŒå°‘ãªã™ãã‚‹ãŸã‚è¨ˆç®—ã§ãã¾ã›ã‚“ (3ãƒãƒ¼ãƒ‰ä»¥ä¸Šå¿…è¦)ã€‚")
else: # num_nodes >= 1000 or num_nodes == 0
    st.write("- åª’ä»‹ä¸­å¿ƒæ€§: ã‚°ãƒ©ãƒ•ã‚µã‚¤ã‚ºãŒå¤§ãã„ã‹ãƒãƒ¼ãƒ‰ãŒãªã„ãŸã‚ã€è¨ˆç®—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")


# è¿‘æ¥ä¸­å¿ƒæ€§
st.markdown("**è¿‘æ¥ä¸­å¿ƒæ€§ (Closeness Centrality)**")
if num_nodes < 500 and num_nodes > 0:
    try:
        closeness_centrality = nx.closeness_centrality(G_to_analyze) # wf_improved is deprecated
        top_closeness = sorted(closeness_centrality.items(), key=lambda x: x[1], reverse=True)[:k_top_centrality]
        st.write(f"- è¿‘æ¥ä¸­å¿ƒæ€§: {[(n, f'{s:.4f}') for n, s in top_closeness]}")
    except Exception as e:
        st.error(f"- è¿‘æ¥ä¸­å¿ƒæ€§ã®è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        st.caption("  - ã‚°ãƒ©ãƒ•ãŒéå¸¸ã«å°ã•ã„ã€ã¾ãŸã¯ç‰¹æ®Šãªæ§‹é€ (ä¾‹:éé€£çµã§ä¸€éƒ¨ã®ãƒãƒ¼ãƒ‰ãŒå­¤ç«‹)ã®å ´åˆã«ç™ºç”Ÿã™ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚")
else:
    st.write("- è¿‘æ¥ä¸­å¿ƒæ€§: ã‚°ãƒ©ãƒ•ã‚µã‚¤ã‚ºãŒå¤§ãã„ã‹ãƒãƒ¼ãƒ‰ãŒãªã„ãŸã‚è¨ˆç®—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")

st.markdown("---")
# --- 4. ãã®ä»–ã®æ€§è³ª ---
st.subheader("4. ğŸ§© ãã®ä»–ã®æ€§è³ª")

# æ¬¡æ•°ç›¸é–¢ (Assortativity)
st.markdown("**æ¬¡æ•°ç›¸é–¢ (Degree Assortativity)**")
if num_edges > 0 and num_nodes > 1: # ã‚¨ãƒƒã‚¸ãŒã‚ã‚Šã€è¤‡æ•°ã®ãƒãƒ¼ãƒ‰ãŒå­˜åœ¨ã™ã‚‹å ´åˆ
    try:
        assortativity = nx.degree_assortativity_coefficient(G_to_analyze)
        st.write(f"- æ¬¡æ•°ç›¸é–¢ (ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢ä¿‚æ•°): {assortativity:.4f}")
        if assortativity > 0.1:
            st.write("  - å‚¾å‘: æ¬¡æ•°ã®é«˜ã„ãƒãƒ¼ãƒ‰åŒå£«ãŒæ¥ç¶šã—ã‚„ã™ã„ (Assortative mixing)")
        elif assortativity < -0.1:
            st.write("  - å‚¾å‘: æ¬¡æ•°ã®é«˜ã„ãƒãƒ¼ãƒ‰ã¨ä½ã„ãƒãƒ¼ãƒ‰ãŒæ¥ç¶šã—ã‚„ã™ã„ (Disassortative mixing)")
        else:
            st.write("  - å‚¾å‘: ç‰¹å®šã®ç›¸é–¢ã¯è¦‹ã‚‰ã‚Œãªã„ (Neutral)")
    except Exception as e: # ä¾‹ãˆã°ã€å…¨ã¦ã®ãƒãƒ¼ãƒ‰ã®æ¬¡æ•°ãŒåŒã˜å ´åˆãªã©
        st.warning(f"- æ¬¡æ•°ç›¸é–¢ã®è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e} (ã‚°ãƒ©ãƒ•ã®æ¬¡æ•°åˆ†å¸ƒãŒå‡ä¸€ã™ãã‚‹å ´åˆãªã©ã«ç™ºç”Ÿã™ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™)")
else:
    st.write("- æ¬¡æ•°ç›¸é–¢: ã‚¨ãƒƒã‚¸ãŒãªã„ã‹ã€ãƒãƒ¼ãƒ‰æ•°ãŒ1ä»¥ä¸‹ãªãŸã‚è¨ˆç®—ã§ãã¾ã›ã‚“ã€‚")


# ãƒªãƒƒãƒã‚¯ãƒ©ãƒ–ä¿‚æ•° (Rich-club coefficient)
st.markdown("**ãƒªãƒƒãƒã‚¯ãƒ©ãƒ–ä¿‚æ•° (Rich-club Coefficient)**")
if num_nodes > 10 and num_edges > 0 :
    try:
        G_for_richclub = G_to_analyze.to_undirected() if G_to_analyze.is_directed() else G_to_analyze
        
        if G_for_richclub.number_of_edges() > 0:
            # Check if there are varying degrees to compute rich-club
            degrees_rc = [d for n,d in G_for_richclub.degree()]
            if len(set(degrees_rc)) > 1 : # è¤‡æ•°ã®ç•°ãªã‚‹æ¬¡æ•°ãŒå­˜åœ¨ã™ã‚‹å ´åˆ
                rc_all_k = nx.rich_club_coefficient(G_for_richclub, normalized=False)
                if rc_all_k:
                    fig_rc, ax_rc = plt.subplots()
                    ax_rc.plot(list(rc_all_k.keys()), list(rc_all_k.values()), marker='o', linestyle='-')
                    ax_rc.set_xlabel("æ¬¡æ•° k")
                    ax_rc.set_ylabel("ãƒªãƒƒãƒã‚¯ãƒ©ãƒ–ä¿‚æ•° Ï†(k)")
                    ax_rc.set_title("ãƒªãƒƒãƒã‚¯ãƒ©ãƒ–ä¿‚æ•° (æ­£è¦åŒ–ãªã—)")
                    ax_rc.grid(True)
                    st.pyplot(fig_rc)
                else:
                    st.write("- ãƒªãƒƒãƒã‚¯ãƒ©ãƒ–ä¿‚æ•°: è¨ˆç®—çµæœãŒç©ºã§ã—ãŸï¼ˆé©åˆ‡ãªæ¬¡æ•°kã®ç¯„å›²ãŒãªã‹ã£ãŸå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼‰ã€‚")
            else:
                st.write("- ãƒªãƒƒãƒã‚¯ãƒ©ãƒ–ä¿‚æ•°: å…¨ã¦ã®ãƒãƒ¼ãƒ‰ã®æ¬¡æ•°ãŒåŒã˜ãŸã‚ã€æœ‰ç›Šãªè¨ˆç®—ãŒã§ãã¾ã›ã‚“ã€‚")
        else:
             st.write("- ãƒªãƒƒãƒã‚¯ãƒ©ãƒ–ä¿‚æ•°: (ç„¡å‘å¤‰æ›å¾Œã®)ã‚°ãƒ©ãƒ•ã«ã‚¨ãƒƒã‚¸ãŒãªã„ãŸã‚è¨ˆç®—ã§ãã¾ã›ã‚“ã€‚")
    except Exception as e:
        st.warning(f"- ãƒªãƒƒãƒã‚¯ãƒ©ãƒ–ä¿‚æ•°ã®è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
else:
    st.write("- ãƒªãƒƒãƒã‚¯ãƒ©ãƒ–ä¿‚æ•°: ã‚°ãƒ©ãƒ•ã‚µã‚¤ã‚ºãŒå°ã•ã„ã‹ã‚¨ãƒƒã‚¸ãŒãªã„ãŸã‚è¨ˆç®—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã€‚")

# ãƒˆãƒ©ã‚¤ã‚¢ãƒ‰æ§‹é€  (Triadic Census) - æœ‰å‘ã‚°ãƒ©ãƒ•ã®ã¿
if G_to_analyze.is_directed() and num_nodes >= 3 and num_nodes < 300:
    st.markdown("**ãƒˆãƒ©ã‚¤ã‚¢ãƒ‰æ§‹é€  (Triadic Census - 3ãƒãƒ¼ãƒ‰é–¢ä¿‚)**")
    try:
        triadic_census_result = nx.triadic_census(G_to_analyze)
        st.write("  - 3ãƒãƒ¼ãƒ‰é–“ã®é–¢ä¿‚æ€§ã®ç¨®é¡ã¨æ•°:")
        df_triads = pd.DataFrame(list(triadic_census_result.items()), columns=['Motif ID', 'Count'])
        st.dataframe(df_triads[df_triads['Count'] > 0].sort_values(by='Count', ascending=False)) # æ•°ãŒ0ã®ã‚‚ã®ã¯éè¡¨ç¤º
        st.caption("""
            Motif IDã®ä¾‹:
            - `003`: 3ãƒãƒ¼ãƒ‰é–“ã«ã‚¨ãƒƒã‚¸ãªã—
            - `012`: Aâ†’B (ä»–ã‚¨ãƒƒã‚¸ãªã—)
            - `102`: Aâ†’B, Bâ†’A (ç›¸äº’ã€ä»–ãªã—)
            - `021D`: Aâ†Bâ†’C (BãŒå…±é€šã®ãƒ•ã‚©ãƒ­ãƒ¼å…ˆ)
            - `021U`: Aâ†’Bâ†C (BãŒå…±é€šã®ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼)
            - `021C`: Aâ†’Bâ†’C (BãŒä¸­ç¶™)
            - `111D`: Aâ†’Bâ†C, Aâ†’C
            - `111U`: Aâ†Bâ†’C, Aâ†C
            - `030T`: Aâ†’B, Bâ†’C, Câ†’A (3ã‚µã‚¤ã‚¯ãƒ«)
            - `030C`: Aâ†Bâ†’C, Aâ†Câ†’B (AãŒB,Cä¸¡æ–¹ã‹ã‚‰ãƒ•ã‚©ãƒ­ãƒ¼ã•ã‚Œã€B,Cé–“ã‚¨ãƒƒã‚¸ãªã—)
            - `201`: Aâ†’B, Bâ†’A, Câ†’A
            - `120D`: Aâ†’B, Bâ†’C, Aâ†’C, Câ†’B
            - `120U`: Aâ†B, Bâ†C, Aâ†C, Câ†A
            - `120C`: Aâ†’B, Bâ†’C, Câ†’A, Aâ†’C (030T + Aâ†’C)
            - `210`: Aâ†’B, Bâ†’A, Aâ†’C, Câ†’A, Bâ†’C (or Câ†’B)
            - `300`: A,B,C å…¨å“¡ç›¸äº’ãƒ•ã‚©ãƒ­ãƒ¼ (å®Œå…¨ã‚°ãƒ©ãƒ•)
            (è©³ç´°ã¯NetworkXãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‚ç…§)
        """)
    except Exception as e:
        st.warning(f"- ãƒˆãƒ©ã‚¤ã‚¢ãƒ‰åˆ†æã®è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
elif G_to_analyze.is_directed() and num_nodes < 3 :
     st.markdown("**ãƒˆãƒ©ã‚¤ã‚¢ãƒ‰æ§‹é€  (Triadic Census - 3ãƒãƒ¼ãƒ‰é–¢ä¿‚)**")
     st.write("- ãƒˆãƒ©ã‚¤ã‚¢ãƒ‰æ§‹é€ : ãƒãƒ¼ãƒ‰æ•°ãŒ3æœªæº€ã®ãŸã‚è¨ˆç®—ã§ãã¾ã›ã‚“ã€‚")
elif G_to_analyze.is_directed() and num_nodes >=300:
     st.markdown("**ãƒˆãƒ©ã‚¤ã‚¢ãƒ‰æ§‹é€  (Triadic Census - 3ãƒãƒ¼ãƒ‰é–¢ä¿‚)**")
     st.write("- ãƒˆãƒ©ã‚¤ã‚¢ãƒ‰æ§‹é€ : ã‚°ãƒ©ãƒ•ã‚µã‚¤ã‚ºãŒå¤§ãã„ãŸã‚è¨ˆç®—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã€‚")


st.markdown("---")
st.caption("å‡¡ä¾‹: N=ãƒãƒ¼ãƒ‰æ•°. ä¸€éƒ¨ã®è¨ˆç®—ï¼ˆå¹³å‡æœ€çŸ­çµŒè·¯é•·ã€åª’ä»‹ä¸­å¿ƒæ€§ã€ãƒˆãƒ©ã‚¤ã‚¢ãƒ‰åˆ†æãªã©ï¼‰ã¯ã‚°ãƒ©ãƒ•ã®ã‚µã‚¤ã‚ºã«ã‚ˆã£ã¦éå¸¸ã«æ™‚é–“ãŒã‹ã‹ã‚‹ãŸã‚ã€å¤§ããªã‚°ãƒ©ãƒ•ã§ã¯ã‚¹ã‚­ãƒƒãƒ—ã¾ãŸã¯è¿‘ä¼¼è¨ˆç®—ã€ã‚‚ã—ãã¯ä¸€éƒ¨ã®é€£çµæˆåˆ†ã®ã¿ã§è¨ˆç®—ã•ã‚Œã¦ã„ã¾ã™ã€‚")